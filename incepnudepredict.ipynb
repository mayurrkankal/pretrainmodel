{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd032518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8028d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede897f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fa735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f227af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa1f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed3557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08beb3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,  \n",
    "                                   shear_range = 0.2,  \n",
    "                                   zoom_range = 0.2,  \n",
    "                                   horizontal_flip = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e328da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec020731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6342 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory('C:/Users/HI/Desktop/mk/adultclassifier/nudedata/train',  \n",
    "                                                 target_size = (256, 256),  \n",
    "                                                 batch_size = 32,  \n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c8e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65207909",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43609b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9677150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1586 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = test_datagen.flow_from_directory('C:/Users/HI/Desktop/mk/adultclassifier/nudedata/val',  \n",
    "                                            target_size = (256, 256),  \n",
    "                                            batch_size = 32,  \n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d24ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43a37a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nude': 0, 'safe': 1}\n"
     ]
    }
   ],
   "source": [
    "class_names = train_data.class_indices\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9918d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc38c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nude': 0, 'safe': 1}\n"
     ]
    }
   ],
   "source": [
    "class_names = test_data.class_indices\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597566c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da37a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72374cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1da36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "#from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa00488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8fd284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648d53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f2d80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(input_shape = (256, 256, 3), include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343e6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130dbe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de747d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "025674e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the following operations:\n",
    "\n",
    "# Flatten the output of our base model to 1 dimension\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "# This time, we will go with a dropout rate of 0.2\n",
    "# Add a final Fully Connected Sigmoid Layer\n",
    "# will again use RMSProp, though you can try out the Adam Optimiser too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322026d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe47b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1bc95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cb7583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 620s 6s/step - loss: 0.2910 - acc: 0.8828 - val_loss: 0.2628 - val_acc: 0.8916\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 629s 6s/step - loss: 0.2566 - acc: 0.8938 - val_loss: 0.2733 - val_acc: 0.8985\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 618s 6s/step - loss: 0.2398 - acc: 0.9039 - val_loss: 0.3051 - val_acc: 0.8852\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 631s 6s/step - loss: 0.2275 - acc: 0.9112 - val_loss: 0.2404 - val_acc: 0.9079\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 619s 6s/step - loss: 0.2340 - acc: 0.9039 - val_loss: 0.2321 - val_acc: 0.9073\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 657s 7s/step - loss: 0.2204 - acc: 0.9072 - val_loss: 0.2602 - val_acc: 0.8871\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 666s 7s/step - loss: 0.2103 - acc: 0.9175 - val_loss: 0.2586 - val_acc: 0.9029\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 678s 7s/step - loss: 0.1835 - acc: 0.9237 - val_loss: 0.2385 - val_acc: 0.9117\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 645s 6s/step - loss: 0.1856 - acc: 0.9156 - val_loss: 0.2414 - val_acc: 0.9048\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 669s 7s/step - loss: 0.1717 - acc: 0.9287 - val_loss: 0.2329 - val_acc: 0.9073\n"
     ]
    }
   ],
   "source": [
    "inc_history = model.fit(train_data, validation_data = test_data, steps_per_epoch = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecee960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f599f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1bad05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 14s 14s/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/nadult.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = inc_history.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ef3fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ff840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb8a14c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/nadult.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = inc_history.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7beac67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e74c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53dbd1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 818ms/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/nadult6.JPG', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = inc_history.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b2ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1375e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7693506d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 696ms/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/download4.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = inc_history.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a396e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54554a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9a2ba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/safe2.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = inc_history.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1d56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798eca90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1922f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 780ms/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/safe.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = inc_history.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4408e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84809d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e71e9b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/adult7.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = inc_history.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483696f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d5685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a46cd6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 836ms/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/nude.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = inc_history.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd16e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fa1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d96c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5e581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760889db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8eac94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce7dd98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4192c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106079c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc504a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff26d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8811f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35ce8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a13b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0966c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8266c7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11520083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbbd93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67f812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d3a84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed43708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b024882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39057651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48366110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e3d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a30705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e603d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec4cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81faca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb69718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2b185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed42f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7accbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d089145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc0d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
