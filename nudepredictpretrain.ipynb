{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0212cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b800a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caeffa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0c8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26fdbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9744e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af346c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,  \n",
    "                                   shear_range = 0.2,  \n",
    "                                   zoom_range = 0.2,  \n",
    "                                   horizontal_flip = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ecfa6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c86653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6342 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory('C:/Users/HI/Desktop/mk/adultclassifier/nudedata/train',  \n",
    "                                                 target_size = (256, 256),  \n",
    "                                                 batch_size = 32,  \n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68fda8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b180454",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6980b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46865a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1586 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = test_datagen.flow_from_directory('C:/Users/HI/Desktop/mk/adultclassifier/nudedata/val',  \n",
    "                                            target_size = (256, 256),  \n",
    "                                            batch_size = 32,  \n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8ce3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce82802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nude': 0, 'safe': 1}\n"
     ]
    }
   ],
   "source": [
    "class_names = train_data.class_indices\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868824d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa63350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nude': 0, 'safe': 1}\n"
     ]
    }
   ],
   "source": [
    "class_names = test_data.class_indices\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22058bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd5fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153bf486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62798094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813,217\n",
      "Trainable params: 813,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#\"\"\"Load the written-from-scratch cnn\"\"\"\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "scratch_model = load_model('C:/Users/HI/Desktop/mk/adultclassifier/nudedata/adpredictor.h5')\n",
    "\n",
    "scratch_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3cc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ace86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2d8eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599e532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acdeab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8783a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f24f84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (256, 256, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99b3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f37fe613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we donâ€™t have to train all the layers, we make them non_trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dc3fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32771a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be213e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2872b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee50cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb9bfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88a1e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 661s 7s/step - loss: 0.6416 - acc: 0.6928 - val_loss: 0.4200 - val_acc: 0.8247\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 666s 7s/step - loss: 0.4800 - acc: 0.7719 - val_loss: 0.3638 - val_acc: 0.8335\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 675s 7s/step - loss: 0.4484 - acc: 0.7975 - val_loss: 0.3573 - val_acc: 0.8392\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 665s 7s/step - loss: 0.4032 - acc: 0.8125 - val_loss: 0.4172 - val_acc: 0.8140\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 747s 7s/step - loss: 0.3887 - acc: 0.8263 - val_loss: 0.4398 - val_acc: 0.8108\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 933s 9s/step - loss: 0.3637 - acc: 0.8397 - val_loss: 0.3305 - val_acc: 0.8487\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 928s 9s/step - loss: 0.3622 - acc: 0.8377 - val_loss: 0.3287 - val_acc: 0.8581\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 944s 9s/step - loss: 0.3498 - acc: 0.8478 - val_loss: 0.3448 - val_acc: 0.8518\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 928s 9s/step - loss: 0.3236 - acc: 0.8575 - val_loss: 0.3051 - val_acc: 0.8695\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 938s 9s/step - loss: 0.3231 - acc: 0.8626 - val_loss: 0.3320 - val_acc: 0.8632\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(x=train_data, validation_data = test_data, steps_per_epoch = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f054511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b341ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec9caa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 947ms/step\n",
      "nude\n",
      "4.495626e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/adult.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = vgghist.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620d90c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgghist.model.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682150f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6822b52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 413ms/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/nadult.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = vgghist.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa1b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab7300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26cdfce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 391ms/step\n",
      "nude\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/adult3.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = vgghist.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1d3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583eae66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa5968d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 241ms/step\n",
      "nude\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/adult4.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = vgghist.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107bb77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f8e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5302ce80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 344ms/step\n",
      "nude\n",
      "4.231915e-28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/adult6.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = vgghist.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be24429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7b7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19cce275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 304ms/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/safe2.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = vgghist.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1735bc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552ff9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c39c56f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 393ms/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/nadult3.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = vgghist.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88465ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdc8d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "101c5755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 336ms/step\n",
      "nude\n",
      "2.0808858e-34\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/nadult4.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = vgghist.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537cd96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82742e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee91908c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "safe\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/nadult7.jpg', target_size = (256, 256))  \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0)  \n",
    "result = vgghist.model.predict(test_image)  \n",
    "\n",
    "if result[0][0] == 1:  \n",
    "  prediction = 'safe'  \n",
    "else:  \n",
    "  prediction = 'nude'  \n",
    "  \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10b92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38dbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "181cb4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:/Users/HI/Desktop/mk/pretrainedmodels\\nudepredict.h5 \n"
     ]
    }
   ],
   "source": [
    "directory = \"C:/Users/HI/Desktop/mk/pretrainedmodels\"\n",
    "name = 'nudepredict.h5'\n",
    "path = os.path.join(directory, name)\n",
    "model.save(path)\n",
    "print('Saved trained model at %s ' % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cd42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cee32e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d359a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "728aca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff736b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea01c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.3316 - acc: 0.8565\n",
      "Epoch 1: saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1581s 8s/step - loss: 0.3316 - acc: 0.8565 - val_loss: 0.3073 - val_acc: 0.8682\n",
      "Epoch 2/10\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.3013 - acc: 0.8712\n",
      "Epoch 2: saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1601s 8s/step - loss: 0.3013 - acc: 0.8712 - val_loss: 0.4987 - val_acc: 0.7913\n",
      "Epoch 3/10\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2871 - acc: 0.8757\n",
      "Epoch 3: saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1637s 8s/step - loss: 0.2871 - acc: 0.8757 - val_loss: 0.3032 - val_acc: 0.8714\n",
      "Epoch 4/10\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2722 - acc: 0.8838\n",
      "Epoch 4: saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1608s 8s/step - loss: 0.2722 - acc: 0.8838 - val_loss: 0.2990 - val_acc: 0.8733\n",
      "Epoch 5/10\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2627 - acc: 0.8896\n",
      "Epoch 5: saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 2234s 11s/step - loss: 0.2627 - acc: 0.8896 - val_loss: 0.3011 - val_acc: 0.8752\n",
      "Epoch 6/10\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2615 - acc: 0.8926\n",
      "Epoch 6: saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 2262s 11s/step - loss: 0.2615 - acc: 0.8926 - val_loss: 0.3463 - val_acc: 0.8594\n",
      "Epoch 7/10\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2474 - acc: 0.8966\n",
      "Epoch 7: saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 2345s 12s/step - loss: 0.2474 - acc: 0.8966 - val_loss: 0.3032 - val_acc: 0.8733\n",
      "Epoch 8/10\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2450 - acc: 0.8997\n",
      "Epoch 8: saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 2083s 10s/step - loss: 0.2450 - acc: 0.8997 - val_loss: 0.3111 - val_acc: 0.8733\n",
      "Epoch 9/10\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2353 - acc: 0.9037\n",
      "Epoch 9: saving model to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1708s 9s/step - loss: 0.2353 - acc: 0.9037 - val_loss: 0.3069 - val_acc: 0.8745\n",
      "Epoch 10/10\n",
      "120/199 [=================>............] - ETA: 8:52 - loss: 0.2125 - acc: 0.9143"
     ]
    }
   ],
   "source": [
    "cp_checkpoint = ModelCheckpoint(\"model\", verbose=1)\n",
    "\n",
    "model.fit(x=train_data,\n",
    "          validation_data=(test_data), \n",
    "          epochs=10, \n",
    "          callbacks=[cp_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02aaea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8932e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f14ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6da674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d99847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d2320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9bb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711aecd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383cf82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5fde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d2237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1573879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca12ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed5cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88432dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
